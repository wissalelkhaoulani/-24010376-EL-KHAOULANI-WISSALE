# Cours de science de donnÃ©es 
# 24010376
# CAC2
# EL KHAOULANI WISSALE
# Ecole national de commerce et de gestion
<img src="photo.jpg" style="height:150px;margin-right:100px"/> 



# RAPPORT PROFESSIONNEL D'ANALYSE
# Projet : SystÃ¨me de DÃ©tection de Fraude FinanciÃ¨re
# Dataset : Fraud Guard Synthetic 2025

---

**Auteur** : Data Science Team  
**Date** : DÃ©cembre 2025  
**Type de Projet** : Classification Binaire SupervisÃ©e  
**CriticitÃ©** : Haute (Enjeux financiers et rÃ©glementaires)

---

## ğŸ“‹ SOMMAIRE EXÃ‰CUTIF

Ce rapport dÃ©taille l'implÃ©mentation d'un systÃ¨me de dÃ©tection de fraude basÃ© sur l'apprentissage automatique, appliquÃ© au dataset **Fraud Guard Synthetic 2025**. Le projet suit rigoureusement les 7 phases du cycle de vie standard de la Data Science, depuis l'analyse mÃ©tier jusqu'Ã  l'audit de performance.

**RÃ©sultats clÃ©s attendus** :
- Identification automatique des transactions frauduleuses
- Minimisation des faux nÃ©gatifs (fraudes non dÃ©tectÃ©es)
- Optimisation du ROC AUC Score (>0.90 visÃ©)

---

## 1ï¸âƒ£ LE CONTEXTE MÃ‰TIER ET LA MISSION

### ğŸ¯ **Le ProblÃ¨me (Business Case)**

Dans le secteur bancaire et financier, la fraude reprÃ©sente un dÃ©fi critique avec des consÃ©quences multiples :

- **Pertes financiÃ¨res directes** : Milliards de dollars perdus annuellement
- **RÃ©putation** : Ã‰rosion de la confiance des clients
- **ConformitÃ© rÃ©glementaire** : Obligations lÃ©gales strictes (PSD2, GDPR)
- **Impact psychologique** : Stress et perte de confiance des victimes

**Objectif stratÃ©gique** : DÃ©velopper un "Assistant IA" en temps rÃ©el capable d'analyser les transactions et de signaler automatiquement les comportements suspects.

---

### âš–ï¸ **L'Enjeu Critique : Matrice des CoÃ»ts d'Erreur AsymÃ©trique**

Contrairement au diagnostic mÃ©dical, ici la matrice des coÃ»ts est inversÃ©e mais tout aussi critique :

| Type d'Erreur | Impact | CoÃ»t MÃ©tier | PrioritÃ© |
|---------------|--------|-------------|----------|
| **Faux Positif (FP)** | Bloquer une transaction lÃ©gitime | âš ï¸ **Moyen** : Frustration client, appels support, perte de ventes | ModÃ©rÃ©e |
| **Faux NÃ©gatif (FN)** | Laisser passer une fraude | ğŸ”´ **CRITIQUE** : Perte financiÃ¨re directe, responsabilitÃ© lÃ©gale | **MAXIMALE** |

**âš ï¸ RÃˆGLE D'OR** : Le systÃ¨me doit **maximiser le Recall (SensibilitÃ©)** pour capturer le maximum de fraudes, quitte Ã  gÃ©nÃ©rer quelques fausses alertes qui seront validÃ©es manuellement par l'Ã©quipe anti-fraude.

**Contrainte secondaire** : Maintenir une **Precision raisonnable** (>70%) pour Ã©viter de saturer les Ã©quipes humaines avec des alertes inutiles.

---

### ğŸ“Š **Les DonnÃ©es (L'Input)**

#### **Source** : Fraud Guard Synthetic 2025 (Kaggle)
- **Nature** : Dataset synthÃ©tique gÃ©nÃ©rÃ© pour simuler des transactions financiÃ¨res rÃ©alistes
- **Avantage** : ConformitÃ© GDPR (pas de donnÃ©es personnelles rÃ©elles)
- **Structure attendue** :

```
Variables typiques dans un dataset de fraude financiÃ¨re :
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Œ Features Temporelles :
   - timestamp / step : Moment de la transaction
   - hour / day_of_week : Patterns temporels

ğŸ“Œ Features Transactionnelles :
   - amount : Montant de la transaction
   - type : Type (PAYMENT, TRANSFER, CASH_OUT, etc.)
   - oldbalanceOrg / newbalanceOrig : Soldes Ã©metteur
   - oldbalanceDest / newbalanceDest : Soldes destinataire

ğŸ“Œ Features Identifiants :
   - nameOrig : ID client Ã©metteur
   - nameDest : ID client destinataire

ğŸ“Œ Target (y) :
   - is_fraud / isFraud : Variable binaire (0 = LÃ©gitime, 1 = Fraude)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

**CaractÃ©ristique critique** : **DÃ©sÃ©quilibre extrÃªme des classes**
- Fraudes rÃ©elles : ~0.1% Ã  3% des transactions (classe minoritaire)
- Transactions lÃ©gitimes : ~97-99.9% (classe majoritaire)

---

## 2ï¸âƒ£ LE CODE PYTHON (LABORATOIRE)

### ğŸ§ª **Architecture du Script**

Le script suit un pattern industriel modulaire en 8 phases :

```python
# PHASE 1 : Acquisition & TÃ©lÃ©chargement (KaggleHub)
# PHASE 2 : Exploration Initiale (Info, Stats, NaN)
# PHASE 3 : Data Wrangling (Nettoyage, Imputation, Encodage)
# PHASE 4 : EDA AvancÃ©e (Visualisations, CorrÃ©lations)
# PHASE 5 : Feature Engineering (CrÃ©ation de variables dÃ©rivÃ©es)
# PHASE 6 : Protocole ExpÃ©rimental (Train/Test Split StratifiÃ©)
# PHASE 7 : Intelligence Artificielle (Random Forest + Class Balancing)
# PHASE 8 : Audit de Performance (MÃ©triques, Courbe ROC, Feature Importance)
```

### ğŸ“¦ **Stack Technologique**

```python
import numpy as np                    # Calcul matriciel
import pandas as pd                   # Manipulation de donnÃ©es tabulaires
import matplotlib.pyplot as plt       # Visualisation statique
import seaborn as sns                 # Visualisation statistique avancÃ©e
import kagglehub                      # Interface Kaggle

# Scikit-Learn : La rÃ©fÃ©rence ML
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, 
    classification_report,
    confusion_matrix, 
    roc_auc_score,      # MÃ©trique clÃ© pour dÃ©sÃ©quilibre
    roc_curve           # Courbe performance
)
```

---

## 3ï¸âƒ£ ANALYSE APPROFONDIE : NETTOYAGE (DATA WRANGLING)

### ğŸ”§ **Le ProblÃ¨me MathÃ©matique du "Vide"**

Les valeurs manquantes (NaN, NULL, None) sont toxiques pour les algorithmes :

1. **AlgÃ¨bre linÃ©aire** : Une seule valeur manquante dans une matrice rend impossible le calcul de distances (euclidienne, Manhattan)
2. **Arbres de dÃ©cision** : Peuvent gÃ©rer les NaN nativement, mais la performance est sous-optimale
3. **RÃ©seaux de neurones** : IncompatibilitÃ© totale avec les NaN

**Diagnostic** :
```python
# Identification des colonnes problÃ©matiques
missing_summary = df.isnull().sum()
missing_pct = (missing_summary / len(df)) * 100

# RÃ¨gle de dÃ©cision :
# - Si < 5% manquant : Imputation
# - Si 5-30% manquant : Imputation + flag binaire "Ã©tait_manquant"
# - Si > 30% manquant : Supprimer la colonne
```

---

### ğŸ› ï¸ **La MÃ©canique de l'Imputation**

#### **StratÃ©gie pour Variables NumÃ©riques** :

```python
imputer = SimpleImputer(strategy='mean')  # ou 'median' si outliers

# Ã‰tape 1 : Apprentissage (fit)
# L'imputer scanne la colonne "amount" sur le Train Set
# Calcul : Î¼ = 2,347.89 â‚¬ (moyenne)
# Stockage en mÃ©moire : imputer.statistics_

# Ã‰tape 2 : Transformation (transform)
# Repasse sur les donnÃ©es et remplace NaN par Î¼
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)  # Utilise Î¼ du train !
```

**Alternatives selon le contexte** :
- `strategy='median'` : Robuste aux outliers (montants extrÃªmes)
- `strategy='most_frequent'` : Pour variables catÃ©gorielles
- KNN Imputer : Utilise les K voisins les plus proches (plus coÃ»teux)

---

### âš ï¸ **Le Coin de l'Expert : Data Leakage (Fuite de DonnÃ©es)**

**ERREUR FATALE Ã€ Ã‰VITER** :

```python
# âŒ MAUVAIS : Imputation AVANT sÃ©paration Train/Test
X_imputed = imputer.fit_transform(X)  # Utilise TOUTES les donnÃ©es
X_train, X_test = train_test_split(X_imputed, ...)

# Pourquoi c'est grave ?
# La moyenne calculÃ©e inclut des informations du futur (test set)
# Le modÃ¨le aura "vu" indirectement les donnÃ©es de test
# Les performances seront surestimÃ©es de 2-5%
```

**âœ… BONNE PRATIQUE INDUSTRIELLE** :

```python
# 1. SÃ©parer d'abord
X_train, X_test, y_train, y_test = train_test_split(X, y, ...)

# 2. Apprendre l'imputation sur le train uniquement
imputer.fit(X_train)  

# 3. Transformer train et test avec les stats du train
X_train_clean = imputer.transform(X_train)
X_test_clean = imputer.transform(X_test)  # Î¼ du train appliquÃ© au test
```

---

### ğŸ·ï¸ **Encodage des Variables CatÃ©gorielles**

Les algorithmes ML ne comprennent que les nombres. Pour les variables textuelles :

```python
# Exemple : type = ['PAYMENT', 'TRANSFER', 'CASH_OUT']

# Option 1 : Label Encoding (pour arbres)
le = LabelEncoder()
df['type_encoded'] = le.fit_transform(df['type'])
# RÃ©sultat : [0, 1, 2] - Ordinal implicite

# Option 2 : One-Hot Encoding (pour modÃ¨les linÃ©aires)
df_encoded = pd.get_dummies(df, columns=['type'], drop_first=True)
# RÃ©sultat : type_TRANSFER, type_CASH_OUT (colonnes binaires)
```

**Pour Random Forest** : Label Encoding suffit (l'arbre gÃ¨re naturellement les catÃ©gories).

---

## 4ï¸âƒ£ ANALYSE APPROFONDIE : EXPLORATION (EDA)

### ğŸ“Š **DÃ©crypter `.describe()`**

```python
df['amount'].describe()
```

| Statistique | Valeur | InterprÃ©tation |
|-------------|--------|----------------|
| **count** | 594,643 | Nombre de valeurs non-nulles |
| **mean** | 2,347.89 | Moyenne (centre de gravitÃ©) |
| **std** | 12,456.31 | Ã‰cart-type (dispersion) - **âš ï¸ Ã‰NORME ici** |
| **min** | 0.01 | Transaction minimale |
| **25% (Q1)** | 134.23 | 25% des transactions < 134â‚¬ |
| **50% (MÃ©diane)** | 876.45 | Valeur centrale (robuste aux outliers) |
| **75% (Q3)** | 3,201.12 | 75% des transactions < 3,201â‚¬ |
| **max** | 10,000,000 | **ğŸš¨ OUTLIER DÃ‰TECTÃ‰** |

**Analyse critique** :
- **Mean (2,347) >> Median (876)** : Distribution fortement asymÃ©trique (skewed)
- **Std Ã©norme** : Variance extrÃªme causÃ©e par des transactions gÃ©antes
- **Max = 10M** : Potentiellement des fraudes ou transactions B2B exceptionnelles

**Action requise** : Transformation logarithmique pour normaliser.

```python
df['amount_log'] = np.log1p(df['amount'])  # log(1+x) pour gÃ©rer les 0
```

---

### ğŸ” **La MulticollinÃ©aritÃ© (ProblÃ¨me de Redondance)**

```python
# Heatmap de corrÃ©lation
correlation_matrix = df.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
```

**Exemple typique dÃ©tectÃ©** :
- `oldbalanceOrg` â†” `newbalanceOrig` : CorrÃ©lation = 0.98
- **Raison mathÃ©matique** : `newbalance = oldbalance - amount`

**Impact selon l'algorithme** :

| Algorithme | Impact MulticollinÃ©aritÃ© | Action |
|------------|-------------------------|--------|
| **Random Forest** | âœ… Aucun problÃ¨me | Garder toutes les variables |
| **RÃ©gression Logistique** | ğŸ”´ Coefficients instables | Supprimer une des deux variables |
| **RÃ©seaux de Neurones** | ğŸŸ¡ Convergence plus lente | Utiliser Dropout ou PCA |

**Pour ce projet** : Random Forest Ã©tant robuste, on conserve toutes les features.

---

### ğŸ“ˆ **Visualisations StratÃ©giques**

#### **1. Distribution des montants par classe** :
```python
sns.boxplot(data=df, x='is_fraud', y='amount')
# HypothÃ¨se : Les fraudes ont-elles des montants plus Ã©levÃ©s ?
```

#### **2. Analyse temporelle** :
```python
df.groupby(['hour', 'is_fraud']).size().unstack().plot()
# Question : Les fraudes sont-elles plus frÃ©quentes la nuit ?
```

#### **3. Analyse par type de transaction** :
```python
pd.crosstab(df['type'], df['is_fraud'], normalize='index')
# Question : Quel type (TRANSFER vs CASH_OUT) est le plus risquÃ© ?
```

---

## 5ï¸âƒ£ ANALYSE APPROFONDIE : MÃ‰THODOLOGIE (SPLIT)

### ğŸ² **Le Concept : Garantie de GÃ©nÃ©ralisation**

**Philosophie ML** : 
> "Le but n'est PAS de mÃ©moriser le passÃ©,  
> mais de PRÃ‰DIRE sur des donnÃ©es JAMAIS VUES."

**Analogie** : 
- **Train Set** = Annales d'examens pour rÃ©viser
- **Test Set** = Sujet rÃ©el de l'examen (inÃ©dit)

Si on triche en rÃ©visant le sujet rÃ©el â†’ Notes excellentes mais compÃ©tences nulles.

---

### âš™ï¸ **Les ParamÃ¨tres sous le Capot**

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,        # Ratio
    random_state=42,      # ReproductibilitÃ©
    stratify=y            # ğŸ”¥ CRITIQUE pour dÃ©sÃ©quilibre
)
```

#### **A. Le Ratio 80/20 (Principe de Pareto)**

| Split | % | Justification |
|-------|---|---------------|
| **Train** | 80% | MajoritÃ© pour capturer la complexitÃ© des motifs de fraude |
| **Test** | 20% | Assez grand pour Ãªtre statistiquement significatif (>1000 fraudes si possible) |

**Alternative pour petits datasets** : 70/30 ou validation croisÃ©e (K-Fold).

---

#### **B. La ReproductibilitÃ© (`random_state=42`)**

```python
# Sans random_state
np.random.shuffle(data)  # RÃ©sultat diffÃ©rent Ã  chaque exÃ©cution

# Avec random_state=42
np.random.seed(42)       # Graine fixe â†’ RÃ©sultats identiques
np.random.shuffle(data)  # Toujours le mÃªme ordre
```

**Impact business** :
- âœ… Collaboration internationale : CollÃ¨gue au Japon obtient mÃªmes rÃ©sultats
- âœ… Debugging : Erreurs reproductibles
- âœ… Validation scientifique : Pairs peuvent vÃ©rifier

**Convention** : 42 est devenu le standard (rÃ©fÃ©rence Ã  "Le Guide du voyageur galactique").

---

#### **C. La Stratification (`stratify=y`) - CRITIQUE POUR LA FRAUDE**

**ProblÃ¨me sans stratification** :

```python
# Dataset : 99% lÃ©gitimes, 1% fraudes
X_train, X_test = train_test_split(X, y, test_size=0.2)

# RÃ©sultat possible (hasard malchanceux) :
# Train : 99.2% lÃ©gitimes, 0.8% fraudes
# Test  : 98.5% lÃ©gitimes, 1.5% fraudes

# âš ï¸ Distribution diffÃ©rente â†’ ModÃ¨le biaisÃ©
```

**Solution avec stratification** :

```python
X_train, X_test = train_test_split(X, y, stratify=y)

# RÃ©sultat garanti :
# Train : 99% lÃ©gitimes, 1% fraudes (exactement comme l'original)
# Test  : 99% lÃ©gitimes, 1% fraudes
```

**MÃ©taphore** : Vous voulez goÃ»ter un gÃ¢teau marbrÃ©. Sans stratification, vous risquez de tomber que sur du chocolat. Avec stratification, chaque bouchÃ©e reflÃ¨te le ratio vanille/chocolat.

---

## 6ï¸âƒ£ FOCUS THÃ‰ORIQUE : L'ALGORITHME RANDOM FOREST ğŸŒ²

### ğŸ¤” **Pourquoi Random Forest pour la Fraude ?**

| CritÃ¨re | Random Forest | RÃ©gression Logistique | XGBoost |
|---------|---------------|----------------------|---------|
| **Gestion non-linÃ©aritÃ©** | âœ… Excellent | âŒ Faible | âœ… Excellent |
| **Robustesse outliers** | âœ… TrÃ¨s bon | âŒ Sensible | ğŸŸ¡ Moyen |
| **InterprÃ©tabilitÃ©** | ğŸŸ¡ Feature importance | âœ… Coefficients clairs | ğŸŸ¡ Feature importance |
| **Vitesse entraÃ®nement** | ğŸŸ¡ Moyenne | âœ… Rapide | âŒ Lent |
| **Gestion dÃ©sÃ©quilibre** | âœ… `class_weight='balanced'` | ğŸŸ¡ NÃ©cessite SMOTE | âœ… `scale_pos_weight` |

**Verdict** : Random Forest = "Couteau suisse" - Excellent compromis performance/simplicitÃ©.

---

### ğŸŒ³ **A. La Faiblesse de l'Individu (Arbre de DÃ©cision)**

Un arbre unique fonctionne par questions successives :

```
                    [Montant > 5000â‚¬ ?]
                     /              \
                   OUI              NON
                   /                  \
         [Type = TRANSFER ?]     [Heure > 22h ?]
           /          \            /          \
        FRAUDE    LÃ‰GITIME    FRAUDE    LÃ‰GITIME
```

**ProblÃ¨me : Haute Variance (Overfitting)**
- L'arbre mÃ©morise le bruit : "Le client #42 avec 5,001â‚¬ Ã  22h01 est fraudeur"
- Sur de nouvelles donnÃ©es, cette rÃ¨gle hyper-spÃ©cifique ne marche plus
- **Performance train = 99%** / **Performance test = 75%** (overfitting)

---

### ğŸŒ²ğŸŒ²ğŸŒ² **B. La Force du Groupe (Bagging)**

**Random Forest = 100 arbres diversifiÃ©s qui votent**

#### **MÃ©canisme 1 : Bootstrapping (DiversitÃ© des Ã‰lÃ¨ves)**

```python
# Dataset original : 1000 transactions
dataset = [T1, T2, T3, ..., T1000]

# Arbre #1 s'entraÃ®ne sur un Ã©chantillon alÃ©atoire AVEC remise
train_tree1 = random_sample(dataset, size=1000, replace=True)
# RÃ©sultat : [T42, T7, T42, T891, T7, ...]  # 42 et 7 apparaissent 2x

# Arbre #2 voit un Ã©chantillon diffÃ©rent
train_tree2 = random_sample(dataset, size=1000, replace=True)
# RÃ©sultat : [T3, T555, T12, T3, T910, ...]

# â†’ Chaque arbre dÃ©veloppe une "expertise" basÃ©e sur une expÃ©rience diffÃ©rente
```

---

#### **MÃ©canisme 2 : Feature Randomness (DiversitÃ© des Questions)**

**C'est LA magie du Random Forest.**

```python
# Dataset : 30 colonnes disponibles
# Mais Ã  chaque nÅ“ud de l'arbre, on ne regarde que âˆš30 â‰ˆ 5 colonnes alÃ©atoires

Arbre #1, NÅ“ud racine :
  Colonnes disponibles : [amount, type, hour, oldbalance, newbalance]
  Meilleure question trouvÃ©e : "amount > 5000â‚¬ ?"

Arbre #2, NÅ“ud racine :
  Colonnes disponibles : [merchant, day, category, balance_diff, flag]
  Meilleure question trouvÃ©e : "merchant = suspect ?"
```

**ConsÃ©quence** :
- Force les arbres Ã  explorer des variables secondaires (texture, symÃ©trie en mÃ©dical ; merchant, timing en fraude)
- Ã‰vite que tous les arbres se focalisent sur la mÃªme variable Ã©vidente (montant)
- RÃ©duit drastiquement la corrÃ©lation entre arbres

---

### ğŸ—³ï¸ **C. Le Consensus (Vote DÃ©mocratique)**

```python
# Transaction suspecte arrive
transaction_nouvelle = [amount=9500â‚¬, type=TRANSFER, hour=3h]

# Chaque arbre vote individuellement
Arbre #1  â†’ FRAUDE
Arbre #2  â†’ LÃ‰GITIME
Arbre #3  â†’ FRAUDE
...
Arbre #100 â†’ FRAUDE

# DÃ©compte final : 73 votes FRAUDE / 27 votes LÃ‰GITIME
# PrÃ©diction finale = FRAUDE (majoritÃ©)
# ProbabilitÃ© = 73% de confiance
```

**PropriÃ©tÃ© mathÃ©matique magique** :
- Les erreurs individuelles (bruit) s'annulent statistiquement
- Le signal commun (vrai motif de fraude) Ã©merge
- **Condition** : Les arbres doivent Ãªtre suffisamment dÃ©corrÃ©lÃ©s (d'oÃ¹ le feature randomness)

---

### âš–ï¸ **D. Gestion du DÃ©sÃ©quilibre : `class_weight='balanced'`**

**ProblÃ¨me sans ajustement** :

```python
# Dataset : 99,000 lÃ©gitimes, 1,000 fraudes
model = RandomForestClassifier()
model.fit(X, y)

# RÃ©sultat : Le modÃ¨le apprend une stratÃ©gie paresseuse
# "Dire toujours LÃ‰GITIME" â†’ 99% d'accuracy !
# Mais 0% de fraudes dÃ©tectÃ©es â†’ Catastrophe mÃ©tier
```

**Solution : PondÃ©ration des classes** :

```python
model = RandomForestClassifier(class_weight='balanced')

# Calcul automatique :
# Poids_FRAUDE = n_total / (2 * n_fraudes) = 100,000 / (2*1,000) = 50
# Poids_LÃ‰GITIME = n_total / (2 * n_lÃ©gitimes) = 100,000 / (2*99,000) â‰ˆ 0.505

# Impact : Chaque fraude mal classÃ©e "coÃ»te" 50x plus cher
# â†’ Force le modÃ¨le Ã  prioriser la dÃ©tection des fraudes
```

---

## 7ï¸âƒ£ ANALYSE APPROFONDIE : Ã‰VALUATION (L'HEURE DE VÃ‰RITÃ‰)

### ğŸ“Š **A. La Matrice de Confusion (Quadrants StratÃ©giques)**

```
                      PRÃ‰DICTION
                   LÃ©gitime | Fraude
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
RÃ‰ALITÃ‰  LÃ©gitime |   TN    |   FP
                  |         | (Fausse Alerte)
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
          Fraude  |   FN    |   TP
                  | (Danger!)|
```

#### **InterprÃ©tation MÃ©tier** :

| Case | Nom | Signification | Impact Business | CoÃ»t |
|------|-----|---------------|-----------------|------|
| **TN** | Vrai NÃ©gatif | LÃ©git dÃ©tectÃ© comme lÃ©git | âœ… Transaction fluide | 0â‚¬ |
| **TP** | Vrai Positif | Fraude dÃ©tectÃ©e | âœ… Argent sauvÃ© | +500â‚¬ (en moyenne) |
| **FP** | Faux Positif | LÃ©git bloquÃ©e par erreur | ğŸŸ¡ Client frustrÃ©, appel SAV | -20â‚¬ |
| **FN** | Faux NÃ©gatif | Fraude passÃ©e inaperÃ§ue | ğŸ”´ **CATASTROPHE** | -500â‚¬ + rÃ©putation |

**RÃ¨gle de dÃ©cision** : 
> 1 FN coÃ»te 25x plus cher qu'1 FP  
> â†’ Accepter 25 FP pour Ã©viter 1 FN

---

### ğŸ“ˆ **B. Les MÃ©triques AvancÃ©es**

#### **1. Accuracy (PrÃ©cision Globale) - âš ï¸ PIÃˆGE POUR FRAUDE**

```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```

**Pourquoi c'est dangereux ?**

```python
# ScÃ©nario : 1% de fraudes
# ModÃ¨le stupide qui dit toujours "LÃ‰GITIME"

TP = 0      # Aucune fraude dÃ©tectÃ©e
TN = 99,000 # Toutes les lÃ©gitimes bien classÃ©es
FP = 0      # Aucune fausse alerte
FN = 1,000  # Toutes les fraudes ratÃ©es

Accuracy = (0 + 99,000) / 100,000 = 99%

# âš ï¸ 99% d'accuracy mais le systÃ¨me est INUTILE !
```

**Verdict** : Ne JAMAIS utiliser l'accuracy seule pour des classes dÃ©sÃ©quilibrÃ©es.

---

#### **2. Precision (QualitÃ© de l'Alarme)**

```
Precision = TP / (TP + FP)
```

**Question** : "Quand le modÃ¨le crie 'FRAUDE', a-t-il raison ?"

```python
# Exemple :
TP = 800  # 800 fraudes correctement dÃ©tectÃ©es
FP = 200  # 200 fausses alertes

Precision = 800 / (800 + 200) = 0.80 = 80%

# InterprÃ©tation :
# Sur 1000 alertes gÃ©nÃ©rÃ©es, 800 sont de vraies fraudes
# 200 sont des fausses alarmes (clients lÃ©gitimes ennuyÃ©s)
```

**Seuil acceptable** : >70% (sinon Ã©quipes anti-fraude submergÃ©es).

---

#### **3. Recall / SensibilitÃ© (Puissance du Filet)**

```
Recall = TP / (TP + FN)
```

**Question** : "Sur toutes les fraudes rÃ©elles, combien le modÃ¨le en attrape ?"

```python
# Exemple :
TP = 800  # 800 fraudes dÃ©tectÃ©es
FN = 200  # 200 fraudes ratÃ©es

Recall = 800 / (800 + 200) = 0.80 = 80%

# InterprÃ©tation :
# Sur 1000 fraudes rÃ©elles, le modÃ¨le en bloque 800
# âš ï¸ 200 fraudes passent entre les mailles (coÃ»t = 200*500â‚¬ = 100,000â‚¬)
```

**Objectif mÃ©tier** : >95% (laisser passer <5% de fraudes).

---

#### **4. F1-Score (Moyenne Harmonique)**

```
F1 = 2 * (Precision * Recall) / (Precision + Recall)
```

**RÃ´le** : Note globale qui pÃ©nalise les dÃ©sÃ©quilibres.

```python
# Cas A : Precision=0.90, Recall=0.50
F1_A = 2 * (0.90*0.50) / (0.90+0.50) = 0.64  # MÃ©diocre

# Cas B : Precision=0.75, Recall=0.75
F1_B = 2 * (0.75*0.75) / (0.75+0.75) = 0.75  # Meilleur Ã©quilibre
```

**Usage** : Comparer deux modÃ¨les avec une seule mÃ©trique honnÃªte.

---

#### **5. ROC AUC Score (MÃ©trique Ultime pour DÃ©sÃ©quilibre)**

**Concept** : Mesure la capacitÃ© du modÃ¨le Ã  sÃ©parer les deux classes, indÃ©pendamment du seuil de dÃ©cision.

```python
# ModÃ¨le parfait : AUC = 1.00 (sÃ©pare 100% des fraudes)
# ModÃ¨le alÃ©atoire : AUC = 0.50 (pile ou face)
# ModÃ¨le acceptable : AUC > 0.90
```

**Avantage** : Robuste au dÃ©sÃ©quilibre des classes (contrairement Ã  l'accuracy).

**Courbe ROC** :
- **Axe X** : Taux de Faux Positifs (FPR)
- **Axe Y** : Taux de Vrais Positifs (TPR = Recall)
- **InterprÃ©tation** : Plus la courbe est proche du coin supÃ©rieur gauche, meilleur est le modÃ¨le

---

### ğŸ¯ **C. StratÃ©gie de Seuil (Threshold Tuning)**

Par dÃ©faut, Scikit-Learn utilise `threshold=0.5` :

```python
# Proba prÃ©dite = 0.51 â†’ FRAUDE
#
